{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning file\n",
    "_This notebook is made by Katoo_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking and dropping missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction unique identifier        0\n",
      "Price                                0\n",
      "Date of Transfer                     0\n",
      "Property Type                        0\n",
      "Old/New                              0\n",
      "Duration                             0\n",
      "Town/City                            0\n",
      "District                             0\n",
      "County                               0\n",
      "PPDCategory Type                     0\n",
      "Record Status - monthly file only    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('subset_2016.csv')\n",
    "print(df.isna().sum())\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking and dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows in the dataset\n",
    "duplicates = df[df.duplicated()]\n",
    "print(f'Number of duplicate rows: {len(duplicates)}')\n",
    "# Check for duplicates\n",
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for skewness in Price column\n",
    "- skewness > 0: right (positive) skewness\n",
    "- skewness < 0: left (negative) skewness \n",
    "- skewness = 0: symmetric distribution\n",
    "\n",
    "Applying log transformations to reduce the right skewness (compressing large values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old skewness: 45.26318224583534\n",
      "New skewness: -0.12253996519765045\n"
     ]
    }
   ],
   "source": [
    "# Check the current skewness\n",
    "old_skew = df[\"Price\"].skew()\n",
    "print(\"Old skewness:\", old_skew)\n",
    "\n",
    "# Apply log transformation to correct right-skewness\n",
    "df['Price'] = np.log(df[\"Price\"])\n",
    "new_skew = df[\"Price\"].skew()\n",
    "print(\"New skewness:\", new_skew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the first few rows of the dataset to have a quick view on the contents of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction unique identifier</th>\n",
       "      <th>Price</th>\n",
       "      <th>Date of Transfer</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Old/New</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Town/City</th>\n",
       "      <th>District</th>\n",
       "      <th>County</th>\n",
       "      <th>PPDCategory Type</th>\n",
       "      <th>Record Status - monthly file only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{31FB4C16-D962-57B9-E050-A8C063053436}</td>\n",
       "      <td>14.436087</td>\n",
       "      <td>2016-03-21</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>KENSINGTON AND CHELSEA</td>\n",
       "      <td>GREATER LONDON</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{31FB4C16-D963-57B9-E050-A8C063053436}</td>\n",
       "      <td>12.860999</td>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>HAMMERSMITH AND FULHAM</td>\n",
       "      <td>GREATER LONDON</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{31FB4C16-D964-57B9-E050-A8C063053436}</td>\n",
       "      <td>13.199324</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>KENSINGTON AND CHELSEA</td>\n",
       "      <td>GREATER LONDON</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{31FB4C16-D965-57B9-E050-A8C063053436}</td>\n",
       "      <td>14.648420</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>KENSINGTON AND CHELSEA</td>\n",
       "      <td>GREATER LONDON</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{31FB4C16-D966-57B9-E050-A8C063053436}</td>\n",
       "      <td>14.790070</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>KENSINGTON AND CHELSEA</td>\n",
       "      <td>GREATER LONDON</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Transaction unique identifier      Price Date of Transfer  \\\n",
       "0  {31FB4C16-D962-57B9-E050-A8C063053436}  14.436087       2016-03-21   \n",
       "1  {31FB4C16-D963-57B9-E050-A8C063053436}  12.860999       2016-04-15   \n",
       "2  {31FB4C16-D964-57B9-E050-A8C063053436}  13.199324       2016-04-21   \n",
       "3  {31FB4C16-D965-57B9-E050-A8C063053436}  14.648420       2016-03-31   \n",
       "4  {31FB4C16-D966-57B9-E050-A8C063053436}  14.790070       2016-03-31   \n",
       "\n",
       "  Property Type Old/New Duration Town/City                District  \\\n",
       "0             F       N        L    LONDON  KENSINGTON AND CHELSEA   \n",
       "1             F       N        L    LONDON  HAMMERSMITH AND FULHAM   \n",
       "2             F       N        L    LONDON  KENSINGTON AND CHELSEA   \n",
       "3             T       N        F    LONDON  KENSINGTON AND CHELSEA   \n",
       "4             F       N        L    LONDON  KENSINGTON AND CHELSEA   \n",
       "\n",
       "           County PPDCategory Type Record Status - monthly file only  \n",
       "0  GREATER LONDON                A                                 A  \n",
       "1  GREATER LONDON                A                                 A  \n",
       "2  GREATER LONDON                A                                 A  \n",
       "3  GREATER LONDON                A                                 A  \n",
       "4  GREATER LONDON                A                                 A  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting year, month and day from the Date of Transfer column and dropping the original column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['Date of Transfer'].str.split('-').str[0]\n",
    "df['month'] = df['Date of Transfer'].str.split('-').str[1]\n",
    "df['day'] = df['Date of Transfer'].str.split('-').str[2]\n",
    "df.drop(columns='Date of Transfer', axis= 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming columns \n",
    "- converting to lowercase and replace spaces with underscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting categorical variables\n",
    "- CategoricalDtype(): creates custom categorical type for the column\n",
    "- .astype(categorical_type): converts column to the new categorical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables\n",
    "property_type = CategoricalDtype(categories=['D', 'S', 'T', 'F'], ordered=False)\n",
    "df[\"property_type\"] = df[\"property_type\"].astype(property_type)\n",
    "old_new = CategoricalDtype(categories=['Y', 'N'], ordered=False)\n",
    "df[\"old/new\"] = df[\"old/new\"].astype(old_new)\n",
    "duration = CategoricalDtype(categories=['F', 'L'], ordered=False)\n",
    "df[\"duration\"] = df[\"duration\"].astype(duration)\n",
    "ppdcategory_type = CategoricalDtype(categories=['A', 'B'], ordered=False)\n",
    "df[\"ppdcategory_type\"] = df[\"ppdcategory_type\"].astype(ppdcategory_type)\n",
    "record_status = CategoricalDtype(categories=['A', 'C', 'D'], ordered=False)\n",
    "df[\"record_status_-_monthly_file_only\"] = df[\"record_status_-_monthly_file_only\"].astype(record_status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding for property_type and label encoding for old/new\n",
    "- Convert categorical column property_type into multiple binary columns\n",
    "- Ensure that one-hot encoded columns contain numeric values (0 and 1) instead of boolean values\n",
    "Label Encoding for old/new\n",
    "- Convert categorical column old/new into numeric labels (1 for 'Y', 0 for 'N')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding for 'property_type'\n",
    "df = pd.get_dummies(df, columns=['property_type'], prefix='property_type_is_', drop_first=False)\n",
    "df[df.filter(like='property_type_is_').columns] = df.filter(like='property_type_is_').astype(int)\n",
    "\n",
    "# Label Encoding for 'old/new'\n",
    "encoder = LabelEncoder()\n",
    "df['old/new'] = encoder.fit_transform(df['old/new'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop(columns = 'transaction_unique_identifier', axis = 1, inplace = True)\n",
    "df.drop(columns = 'duration', axis = 1, inplace = True)\n",
    "df.drop(columns = 'ppdcategory_type', axis = 1, inplace = True)\n",
    "df.drop(columns = 'record_status_-_monthly_file_only', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier detection and removel in the price column\n",
    "- interquartile range method \n",
    "    - calculate IQR\n",
    "    - set bounds\n",
    "    - detect outliers\n",
    "    - count outliers\n",
    "    - clip outliers\n",
    "    - verify clipping\n",
    "- alternative IQR method (in comment)\n",
    "    - instead of clipping data -> removing it\n",
    "    - rows where price is outside the acceptable range are removed\n",
    "    - count number of removed rows\n",
    "- z-score method (in comment)\n",
    "    - calculate z-score\n",
    "    - identify outliers\n",
    "    - filter data so only the entries that are not outliers are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10211 entries having 'Price' value lower than  10.486511795814852\n",
      "14958 entries having 'Price' value greater than 14.063110219802613\n",
      "0 entries having 'Price' value lower than 10.486511795814852\n",
      "0 entries having 'Price' value greater than 14.063110219802613\n"
     ]
    }
   ],
   "source": [
    "# Remove outliers\n",
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "higher = Q3 + 1.5 * IQR\n",
    "\n",
    "price_outliers_below = df.loc[df['price'] < lower]\n",
    "price_outliers_abow = df.loc[df['price'] > higher]\n",
    "\n",
    "print(price_outliers_below['price'].count(), \"entries having 'Price' value lower than \", lower)\n",
    "print(price_outliers_abow['price'].count(), \"entries having 'Price' value greater than\", higher)\n",
    "\n",
    "df[\"price\"] = df[\"price\"].clip(lower=lower, upper=higher)\n",
    "\n",
    "# Identify outliers\n",
    "price_outliers_below = df.loc[df['price'] < lower]\n",
    "price_outliers_above = df.loc[df['price'] > higher]\n",
    "\n",
    "# Print outlier counts\n",
    "print(price_outliers_below['price'].count(), \"entries having 'Price' value lower than\", lower)\n",
    "print(price_outliers_above['price'].count(), \"entries having 'Price' value greater than\", higher)\n",
    "\n",
    "# Q1 = df['price'].quantile(0.25)\n",
    "# Q3 = df['price'].quantile(0.75)\n",
    "# IQR = Q3 - Q1\n",
    "# lower_bound = Q1 - 1.5 * IQR\n",
    "# upper_bound = Q3 + 1.5 * IQR\n",
    "# df = df[(df['price'] >= lower_bound) & (df['price'] <= upper_bound)]\n",
    "# outlier_count = df.shape[0] - df[(df['price'] >= lower_bound) & (df['price'] <= upper_bound)].shape[0]\n",
    "# print(f\"Removed {outlier_count} outlier rows from 'price' column.\")\n",
    "\n",
    "# z_scores = stats.zscore(df['price'])\n",
    "# abs_z_scores = abs(z_scores)\n",
    "# outliers = (abs_z_scores < 2)  # Keeping data within 2 standard deviations\n",
    "# df = df[outliers]\n",
    "# # Display the outliers\n",
    "# print(f\"Number of outliers detected using Z-Score: {outliers.shape[0]}\")\n",
    "# print(outliers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying most frequent price\n",
    "- .mode[0]: extracts first mode value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent price: 14.063110219802613\n",
      "14958 rows have this price value.\n"
     ]
    }
   ],
   "source": [
    "spike_value = df['price'].mode()[0]\n",
    "print(f\"Most frequent price: {spike_value}\")\n",
    "print(df[df['price'] == spike_value].shape[0], \"rows have this price value.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the final cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning complete. Cleaned file saved as 'cleaned_subset.csv'.\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('cleaned_subset.csv', index=False)\n",
    "print(\"Data cleaning complete. Cleaned file saved as 'cleaned_subset.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
