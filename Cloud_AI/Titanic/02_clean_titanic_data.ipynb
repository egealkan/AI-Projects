{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Notebook\n",
    "Contributors:\n",
    "\n",
    "**Egemen Alkan**: Designed and implemented the steps for data cleaning, including removing irrelevant columns, handling missing values, and addressing outliers.\n",
    "Objective:\n",
    "Prepare the Titanic dataset for analysis by cleaning and preprocessing the data. This includes renaming columns, handling missing values, addressing outliers, and saving the cleaned dataset for further use in machine learning models.\n",
    "\n",
    "Overview of Tasks:\n",
    "\n",
    "Rename Columns: Standardize column names to make them easier to use programmatically.\n",
    "Drop Irrelevant Columns: Remove unnecessary columns such as name, ticket, and cabin that are not useful for predictive modeling.\n",
    "Handle Missing Values: Fill missing values in key columns (age, embarked) and remove rows with missing fare values.\n",
    "Handle Outliers: Identify and filter out extreme values in the age column using the IQR (Interquartile Range) method.\n",
    "Save the Cleaned Dataset: Export the cleaned dataset to a CSV file for use in future analysis or machine learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Dataset Link:\n",
    "**https://www.kaggle.com/datasets/yasserh/titanic-dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Titanic Dataset\n",
    "\n",
    "- Objective: Load the Titanic dataset from a CSV file into a pandas DataFrame named titanic_df.\n",
    "- Why: The raw dataset needs to be cleaned and prepared for analysis or machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "titanic_df = pd.read_csv('../data/titanic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rename Columns\n",
    "\n",
    "- Objective: Standardize column names by:\n",
    "    - Converting all column names to lowercase.\n",
    "    - Replacing spaces with underscores (_).\n",
    "- Why: This makes the column names easier to handle in code (especially in programming environments sensitive to casing or spaces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.columns = titanic_df.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Drop Irrelevant Columns\n",
    "\n",
    "- Objective: Remove columns that are deemed irrelevant for analysis or modeling:\n",
    "    - name: Not typically useful for prediction.\n",
    "    - ticket: Unique values, so it doesn't contribute useful information.\n",
    "    - cabin: Often has too many missing values and may not be predictive.\n",
    "- Why: Reduces noise and keeps the dataset focused on relevant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.drop(columns=['name', 'ticket', 'cabin'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Handle Missing Values\n",
    "\n",
    "- Objective: Address missing data for key columns:\n",
    "    - age: Missing values are replaced with the median age, as it's less sensitive to outliers compared to the mean.\n",
    "    - embarked: Missing values are filled with the mode (most frequent value), assuming it's representative of most passengers.\n",
    "    - fare: Rows with missing values in the fare column are dropped because fare is crucial for analysis and cannot easily be inferred.\n",
    "- Why: Missing data can cause issues in analysis or modeling, so these steps ensure the dataset is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing 'age' with median, 'embarked' with mode, and drop rows with missing 'fare'\n",
    "titanic_df['age'].fillna(titanic_df['age'].median(), inplace=True)\n",
    "titanic_df['embarked'].fillna(titanic_df['embarked'].mode()[0], inplace=True)\n",
    "titanic_df.dropna(subset=['fare'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Handle Outliers in the age Column\n",
    "\n",
    "- Objective: Remove extreme outliers in the age column using the IQR (Interquartile Range) method:\n",
    "    - Calculate Q1 (25th percentile) and Q3 (75th percentile).\n",
    "    - Compute the IQR as Q3 - Q1.\n",
    "    - Define acceptable values for age:\n",
    "        - Lower bound: Q1 - 1.5 * IQR.\n",
    "        - Upper bound: Q3 + 1.5 * IQR.\n",
    "    - Keep only rows where age falls within these bounds.\n",
    "- Why: Outliers can distort analysis and models, so removing them ensures the age distribution is more representative of the majority of passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the interquartile range (IQR)\n",
    "Q1 = titanic_df['age'].quantile(0.25)\n",
    "Q3 = titanic_df['age'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Determine lower and upper bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out rows where 'age' is outside these bounds\n",
    "titanic_df = titanic_df[(titanic_df['age'] >= lower_bound) & (titanic_df['age'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save the Cleaned Dataset\n",
    "\n",
    "- Objective: Save the cleaned and preprocessed dataset to a new CSV file named titanic_cleaned.csv in the ../data/ directory.\n",
    "- Why: The cleaned dataset can be used for further analysis, visualization, or machine learning without repeating the cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.to_csv('../data/titanic_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
